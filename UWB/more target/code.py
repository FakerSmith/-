"""
U-Netå¤šç›®æ ‡æ£€æµ‹ - ç®€æ´ç‰ˆ
å¤„ç†æ–‡ä»¶: 20251229_stop_rear_middle_b22_5_h_90_dyn_id_0x723_RX2.json
"""

import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import matplotlib.pyplot as plt
import json
import os
import sys

print("=" * 60)
print("U-Netå¤šç›®æ ‡æ£€æµ‹ç³»ç»Ÿ")
print("=" * 60)

# ===================== 1. åŠ è½½æ•°æ® =====================
file_path = r"C:\Users\FakerSmith\Documents\CSDocument\UWB\more target\20251229_stop_rear_middle_b22_5_h_90_dyn_id_0x723_RX2.json"

try:
    with open(file_path, 'r') as f:
        data = json.load(f)
    print(f"âœ… æˆåŠŸåŠ è½½æ–‡ä»¶: {os.path.basename(file_path)}")
except Exception as e:
    print(f"âŒ åŠ è½½æ–‡ä»¶å¤±è´¥: {e}")
    print(f"è¯·æ£€æŸ¥æ–‡ä»¶è·¯å¾„: {file_path}")
    input("æŒ‰Enteré”®é€€å‡º...")
    sys.exit(1)

# æå–CIRæ•°æ®
if 'CIR_DATA' in data:
    cir_data = np.array(data['CIR_DATA'], dtype=np.float32)
    print(f"ğŸ“Š æ•°æ®ç»´åº¦: {cir_data.shape}")
    print(f"ğŸ“ˆ æ ·æœ¬æ•°é‡: {len(cir_data)}")
    print(f"ğŸ“ æ¯ä¸ªæ ·æœ¬é•¿åº¦: {len(cir_data[0])}")
else:
    print("âŒ æ–‡ä»¶ä¸­æ²¡æœ‰æ‰¾åˆ°CIR_DATAå­—æ®µ")
    sys.exit(1)

# ===================== 2. æ•°æ®é¢„å¤„ç† =====================
print("\nğŸ”§ æ•°æ®é¢„å¤„ç†ä¸­...")

def preprocess_signal(signal):
    """é¢„å¤„ç†å•ä¸ªCIRä¿¡å·"""
    # 1. å»é™¤åŸºçº¿
    baseline = np.mean(signal[-10:])
    signal = signal - baseline
    
    # 2. å½’ä¸€åŒ–
    signal_min, signal_max = signal.min(), signal.max()
    if signal_max - signal_min > 0:
        signal = (signal - signal_min) / (signal_max - signal_min)
    
    # 3. è½¬æ¢ä¸º2Då›¾åƒ (32x32)
    signal = signal[:1024]  # å–å‰1024ä¸ªç‚¹
    signal_2d = signal.reshape(32, 32)
    
    return signal_2d

# å¤„ç†æ‰€æœ‰æ ·æœ¬
processed_data = []
for i in range(len(cir_data)):
    processed_2d = preprocess_signal(cir_data[i])
    processed_data.append(processed_2d)

processed_data = np.array(processed_data)
print(f"ğŸ“Š å¤„ç†åæ•°æ®ç»´åº¦: {processed_data.shape}")

# ===================== 3. U-Netæ¨¡å‹ =====================
class SimpleUNet(nn.Module):
    """ç®€åŒ–çš„U-Netæ¨¡å‹"""
    def __init__(self):
        super(SimpleUNet, self).__init__()
        
        # ç¼–ç å™¨
        self.enc1 = self.conv_block(1, 32)
        self.enc2 = self.conv_block(32, 64)
        self.enc3 = self.conv_block(64, 128)
        self.enc4 = self.conv_block(128, 256)
        
        # è§£ç å™¨
        self.up3 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)
        self.dec3 = self.conv_block(256, 128)
        
        self.up2 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)
        self.dec2 = self.conv_block(128, 64)
        
        self.up1 = nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2)
        self.dec1 = self.conv_block(64, 32)
        
        # è¾“å‡ºå±‚
        self.final = nn.Conv2d(32, 1, kernel_size=1)
        
    def conv_block(self, in_channels, out_channels):
        """å·ç§¯å—"""
        return nn.Sequential(
            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True)
        )
    
    def forward(self, x):
        # ç¼–ç å™¨
        e1 = self.enc1(x)
        p1 = F.max_pool2d(e1, 2)
        
        e2 = self.enc2(p1)
        p2 = F.max_pool2d(e2, 2)
        
        e3 = self.enc3(p2)
        p3 = F.max_pool2d(e3, 2)
        
        e4 = self.enc4(p3)
        
        # è§£ç å™¨
        d3 = self.up3(e4)
        d3 = torch.cat([e3, d3], dim=1)
        d3 = self.dec3(d3)
        
        d2 = self.up2(d3)
        d2 = torch.cat([e2, d2], dim=1)
        d2 = self.dec2(d2)
        
        d1 = self.up1(d2)
        d1 = torch.cat([e1, d1], dim=1)
        d1 = self.dec1(d1)
        
        # è¾“å‡º
        output = torch.sigmoid(self.final(d1))
        return output

# ===================== 4. è®­ç»ƒå‡†å¤‡ =====================
print("\nğŸ¤– å‡†å¤‡è®­ç»ƒ...")

# è®¾å¤‡é€‰æ‹©
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"ğŸ–¥ï¸  ä½¿ç”¨è®¾å¤‡: {device}")

# å‡†å¤‡è®­ç»ƒæ•°æ®
train_data = processed_data[:800]  # å‰800ä¸ªæ ·æœ¬ç”¨äºè®­ç»ƒ
test_data = processed_data[800:]   # å‰©ä¸‹çš„ç”¨äºæµ‹è¯•

# è½¬æ¢ä¸ºPyTorchå¼ é‡
train_tensor = torch.FloatTensor(train_data).unsqueeze(1)  # [800, 1, 32, 32]
test_tensor = torch.FloatTensor(test_data).unsqueeze(1)    # [n, 1, 32, 32]

print(f"ğŸ“š è®­ç»ƒé›†å¤§å°: {len(train_tensor)}")
print(f"ğŸ“š æµ‹è¯•é›†å¤§å°: {len(test_tensor)}")

# ===================== 5. è®­ç»ƒå‡½æ•° =====================
def train_model(model, train_data, epochs=20, lr=0.001):
    """è®­ç»ƒæ¨¡å‹"""
    model = model.to(device)
    criterion = nn.MSELoss()  # ä½¿ç”¨MSEæŸå¤±
    optimizer = optim.Adam(model.parameters(), lr=lr)
    
    losses = []
    
    print(f"\nğŸ¯ å¼€å§‹è®­ç»ƒï¼Œå…± {epochs} è½®...")
    for epoch in range(epochs):
        model.train()
        epoch_loss = 0
        
        # æ‰“ä¹±æ•°æ®
        indices = torch.randperm(len(train_data))
        
        for i in range(0, len(train_data), 32):  # æ‰¹æ¬¡å¤§å°32
            batch_indices = indices[i:i+32]
            batch = train_data[batch_indices].to(device)
            
            # å‰å‘ä¼ æ’­
            output = model(batch)
            
            # æŸå¤±è®¡ç®—ï¼ˆè‡ªç¼–ç å™¨ï¼šé‡å»ºæŸå¤±ï¼‰
            loss = criterion(output, batch)
            
            # åå‘ä¼ æ’­
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            
            epoch_loss += loss.item()
        
        avg_loss = epoch_loss / (len(train_data) // 32)
        losses.append(avg_loss)
        
        if (epoch + 1) % 5 == 0:
            print(f"  è½®æ¬¡ {epoch+1:3d}/{epochs} | æŸå¤±: {avg_loss:.6f}")
    
    return losses

# ===================== 6. ä¸»è®­ç»ƒæµç¨‹ =====================
print("\n" + "=" * 60)
print("å¼€å§‹è®­ç»ƒU-Netæ¨¡å‹...")
print("=" * 60)

# åˆ›å»ºæ¨¡å‹
model = SimpleUNet()
print(f"ğŸ“ æ¨¡å‹å‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")

# è®­ç»ƒæ¨¡å‹
train_data_tensor = train_tensor.to(device)
losses = train_model(model, train_data_tensor, epochs=30, lr=0.001)

# ===================== 7. å¯è§†åŒ–ç»“æœ =====================
print("\nğŸ“Š å¯è§†åŒ–ç»“æœ...")

# ç»˜åˆ¶æŸå¤±æ›²çº¿
plt.figure(figsize=(10, 5))
plt.subplot(1, 2, 1)
plt.plot(losses)
plt.title('è®­ç»ƒæŸå¤±æ›²çº¿')
plt.xlabel('è½®æ¬¡')
plt.ylabel('æŸå¤±')
plt.grid(True, alpha=0.3)

# æµ‹è¯•æ¨¡å‹
model.eval()
with torch.no_grad():
    # é€‰æ‹©ä¸€ä¸ªæµ‹è¯•æ ·æœ¬
    test_sample = test_tensor[0:1].to(device)
    output = model(test_sample)
    
    # è½¬æ¢ä¸ºnumpyç”¨äºæ˜¾ç¤º
    input_img = test_sample[0, 0].cpu().numpy()
    output_img = output[0, 0].cpu().numpy()
    
    # ç»˜åˆ¶è¾“å…¥å’Œè¾“å‡º
    plt.subplot(2, 2, 2)
    plt.imshow(input_img, cmap='viridis')
    plt.title('è¾“å…¥ä¿¡å·')
    plt.colorbar()
    
    plt.subplot(2, 2, 3)
    plt.imshow(output_img, cmap='viridis')
    plt.title('é‡å»ºä¿¡å·')
    plt.colorbar()
    
    plt.subplot(2, 2, 4)
    diff = np.abs(input_img - output_img)
    plt.imshow(diff, cmap='hot')
    plt.title('å·®å¼‚å›¾')
    plt.colorbar()

plt.tight_layout()
plt.show()

# ===================== 8. ç›®æ ‡æ£€æµ‹ =====================
print("\nğŸ¯ ç›®æ ‡æ£€æµ‹ä¸­...")

def detect_targets(output_map, threshold=0.5):
    """ä»è¾“å‡ºå›¾ä¸­æ£€æµ‹ç›®æ ‡"""
    # äºŒå€¼åŒ–
    binary_map = (output_map > threshold).astype(np.uint8)
    
    # å¯»æ‰¾è¿é€šåŒºåŸŸ
    from scipy import ndimage
    labeled_array, num_features = ndimage.label(binary_map)
    
    targets = []
    for i in range(1, num_features + 1):
        # è·å–è¯¥åŒºåŸŸçš„ä½ç½®
        positions = np.argwhere(labeled_array == i)
        if len(positions) > 0:
            # è®¡ç®—ä¸­å¿ƒä½ç½®
            center_y, center_x = positions.mean(axis=0)
            # è®¡ç®—åŒºåŸŸå¤§å°
            size = len(positions)
            # è®¡ç®—ç½®ä¿¡åº¦
            confidence = output_map[positions[:, 0], positions[:, 1]].mean()
            
            targets.append({
                'id': i,
                'center': (float(center_x), float(center_y)),
                'size': size,
                'confidence': float(confidence)
            })
    
    return targets

# å¯¹æµ‹è¯•æ ·æœ¬è¿›è¡Œç›®æ ‡æ£€æµ‹
with torch.no_grad():
    test_batch = test_tensor[:5].to(device)
    outputs = model(test_batch)
    
    print(f"\næ£€æµ‹åˆ° {len(test_batch)} ä¸ªæ ·æœ¬çš„ç›®æ ‡:")
    for i in range(len(test_batch)):
        output_np = outputs[i, 0].cpu().numpy()
        targets = detect_targets(output_np, threshold=0.3)
        
        print(f"\næ ·æœ¬ {i+1}:")
        print(f"  â””â”€ æ£€æµ‹åˆ° {len(targets)} ä¸ªæ½œåœ¨ç›®æ ‡")
        for j, target in enumerate(targets):
            print(f"    ç›®æ ‡ {j+1}: ä½ç½® ({target['center'][0]:.1f}, {target['center'][1]:.1f}), "
                  f"å¤§å° {target['size']}, ç½®ä¿¡åº¦ {target['confidence']:.3f}")

# ===================== 9. ä¿å­˜æ¨¡å‹ =====================
print("\nğŸ’¾ ä¿å­˜æ¨¡å‹ä¸­...")
try:
    torch.save({
        'model_state_dict': model.state_dict(),
        'input_shape': (1, 32, 32),
        'losses': losses
    }, 'unet_target_detector.pth')
    print("âœ… æ¨¡å‹å·²ä¿å­˜ä¸º: unet_target_detector.pth")
except Exception as e:
    print(f"âš ï¸  ä¿å­˜æ¨¡å‹æ—¶å‡ºé”™: {e}")

# ===================== 10. åˆ†ææŠ¥å‘Š =====================
print("\n" + "=" * 60)
print("åˆ†ææŠ¥å‘Š")
print("=" * 60)

# ç»Ÿè®¡ä¿¡æ¯
print(f"ğŸ“Š æ•°æ®ç»Ÿè®¡:")
print(f"  åŸå§‹æ•°æ®ç‚¹æ•°: {len(cir_data[0])}")
print(f"  å¤„ç†åçš„å›¾åƒå¤§å°: 32Ã—32")
print(f"  æ€»æ ·æœ¬æ•°: {len(cir_data)}")
print(f"  è®­ç»ƒæ ·æœ¬æ•°: {len(train_tensor)}")
print(f"  æµ‹è¯•æ ·æœ¬æ•°: {len(test_tensor)}")

# æ¨¡å‹ä¿¡æ¯
print(f"\nğŸ¤– æ¨¡å‹ä¿¡æ¯:")
print(f"  æ€»å‚æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")
print(f"  è®­ç»ƒè½®æ¬¡: {len(losses)}")
print(f"  æœ€ç»ˆæŸå¤±: {losses[-1]:.6f}")
print(f"  æŸå¤±ä¸‹é™: {((losses[0] - losses[-1]) / losses[0] * 100):.1f}%")

# æ€§èƒ½è¯„ä¼°
if len(test_tensor) > 0:
    with torch.no_grad():
        test_outputs = model(test_tensor.to(device))
        mse = F.mse_loss(test_outputs, test_tensor.to(device)).item()
        print(f"\nğŸ“ˆ æ€§èƒ½è¯„ä¼°:")
        print(f"  æµ‹è¯•é›†MSE: {mse:.6f}")
        print(f"  æµ‹è¯•é›†PSNR: {10 * np.log10(1.0 / mse):.2f} dB")

print("\n" + "=" * 60)
print("ğŸ‰ å¤„ç†å®Œæˆï¼")
print("=" * 60)
print("\nğŸ“‹ ç”Ÿæˆçš„æ–‡ä»¶:")
print("  âœ“ è®­ç»ƒæŸå¤±å›¾")
print("  âœ“ è¾“å…¥/è¾“å‡ºå¯¹æ¯”å›¾")
print("  âœ“ ç›®æ ‡æ£€æµ‹ç»“æœ")
print("  âœ“ æ¨¡å‹æ–‡ä»¶: unet_target_detector.pth")

print("\nğŸ”§ ä½¿ç”¨æ–¹æ³•:")
print("  1. ä¿®æ”¹é˜ˆå€¼å‚æ•°å¯ä»¥è°ƒæ•´æ£€æµ‹çµæ•åº¦")
print("  2. å¢åŠ è®­ç»ƒè½®æ¬¡å¯ä»¥æé«˜é‡å»ºè´¨é‡")
print("  3. è°ƒæ•´å›¾åƒå¤§å°å¯ä»¥é€‚åº”ä¸åŒé•¿åº¦çš„æ•°æ®")

input("\næŒ‰Enteré”®é€€å‡ºç¨‹åº...")